{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib2 import Request, urlopen\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code for collecting post data from Facebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUrlJson(url):\n",
    "    request = Request(url, headers={'User-Agent' : \"Chrome\"})\n",
    "    response = urlopen(request)\n",
    "    result = response.read().decode('utf-8')\n",
    "    res_json = json.loads(result)\n",
    "    return res_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_id = 'leehsienloong'\n",
    "fields = [\"shares\", \"story\", \"message\", \"status_type\", \"created_time\"]\n",
    "token = '2031478377138497|7I-9i_f_CU_TMkXpLDLN_cdl8Y0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieveFacebookPosts(page_id, token, fields, num_pages):\n",
    "    i = 0\n",
    "    url = 'https://graph.facebook.com/{}/posts?access_token={}&fields={}'.format(page_id, token, (\",\").join(fields))\n",
    "    results = pd.DataFrame()\n",
    "    while True:\n",
    "        i += 1\n",
    "        res_json = getUrlJson(url)\n",
    "        result = pd.read_json(json.dumps(res_json['data']))\n",
    "        #result = pd.io.json.json_normalize(res_json['data'])\n",
    "        results = results.append(result)\n",
    "        try:\n",
    "            url = res_json['paging']['next']\n",
    "            # print(url)\n",
    "        except KeyError:\n",
    "            print(\"no more posts\")\n",
    "            break\n",
    "        if i >= num_pages:\n",
    "            print(\"stopping on provided limit\")\n",
    "            break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lhl_posts = retrieveFacebookPosts('leehsienloong', token, fields, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lhl_posts['share_count'] = lhl_posts['shares'].apply(lambda x: x['count'] if type(x) is dict else x)\n",
    "#del lhl_posts['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lhl_posts.to_json(\"data/facebook.json\", orient=\"records\", date_format=\"iso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Exercise \n",
    "#### Reading and viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb = pd.read_json(\"data/facebook.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>share_count</th>\n",
       "      <th>status_type</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-22 12:08:26</td>\n",
       "      <td>125845680811480_1549087385153962</td>\n",
       "      <td>The Central Singapore Community Development Co...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>added_photos</td>\n",
       "      <td>Lee Hsien Loong added 2 new photos to the albu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-21 01:00:00</td>\n",
       "      <td>125845680811480_1547453581984009</td>\n",
       "      <td>In many ways, racial harmony is like making mu...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>added_photos</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-20 02:03:51</td>\n",
       "      <td>125845680811480_1546478675414833</td>\n",
       "      <td>Race, language, and religion are fault lines t...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>added_photos</td>\n",
       "      <td>Lee Hsien Loong added 9 new photos to the albu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-19 02:03:34</td>\n",
       "      <td>125845680811480_1545406252188742</td>\n",
       "      <td>Puan Noor Aishah was only 26 when her husband,...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>added_photos</td>\n",
       "      <td>Lee Hsien Loong added 3 new photos to the albu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-18 14:21:53</td>\n",
       "      <td>125845680811480_1544866842242683</td>\n",
       "      <td>Spent a fun morning visiting two preschools in...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>added_video</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_time                                id  \\\n",
       "0 2017-07-22 12:08:26  125845680811480_1549087385153962   \n",
       "1 2017-07-21 01:00:00  125845680811480_1547453581984009   \n",
       "2 2017-07-20 02:03:51  125845680811480_1546478675414833   \n",
       "3 2017-07-19 02:03:34  125845680811480_1545406252188742   \n",
       "4 2017-07-18 14:21:53  125845680811480_1544866842242683   \n",
       "\n",
       "                                             message  share_count  \\\n",
       "0  The Central Singapore Community Development Co...         54.0   \n",
       "1  In many ways, racial harmony is like making mu...        103.0   \n",
       "2  Race, language, and religion are fault lines t...        170.0   \n",
       "3  Puan Noor Aishah was only 26 when her husband,...        120.0   \n",
       "4  Spent a fun morning visiting two preschools in...        338.0   \n",
       "\n",
       "    status_type                                              story  \n",
       "0  added_photos  Lee Hsien Loong added 2 new photos to the albu...  \n",
       "1  added_photos                                               None  \n",
       "2  added_photos  Lee Hsien Loong added 9 new photos to the albu...  \n",
       "3  added_photos  Lee Hsien Loong added 3 new photos to the albu...  \n",
       "4   added_video                                               None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2528 entries, 0 to 2527\n",
      "Data columns (total 6 columns):\n",
      "created_time    2528 non-null datetime64[ns]\n",
      "id              2528 non-null object\n",
      "message         2467 non-null object\n",
      "share_count     2443 non-null float64\n",
      "status_type     2513 non-null object\n",
      "story           1310 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 138.2+ KB\n"
     ]
    }
   ],
   "source": [
    "fb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set created_time as the dataframe's index and sort the dataframe by the datetime index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the datetime index from utc to Asia / Singapore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the weekly counts of posts from 2012 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the weekly share count totals from 2012 onwards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which are the top five weeks in terms of total share counts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What event and posts resulted in the highest weekly share count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if we can predict the popularity of FB posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a boxplot of share count, adjust the axis limits as necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's indicate a popular post as one with share count > 200. Create a new column 'popular' to reflect this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First replace all null values in the message column with the story column and the remaining null values with an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next let's split the data into a train and test dataset with posts from 2017 onwards being in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a CountVectorizer using english stopwords and with 500 maximum features and ngram range = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and transform the message column of the training dataset with the CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the same CountVectorizer, transform the message column of the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lnitialize a RandomForestClassifier with max depth of 5 number of estimators 10 and min samples per leaf 5 and random_state = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the classifier using the bag of words as the independent variable / predictors and popular as the dependent variable we want to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which words have the highest feature importances? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the roc_auc_score for predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's re-implement the model using pipelines and GridSearchCV\n",
    "#### Create a pipeline with two stages, the first being the count vectorizer and the second the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the pipeline using the training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the pipeline to make predictions on the test dataset and calculate the roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a GridSearch CV using the pipeline as the estimator, and passing it a set of parameters with varying values for parameters such as max_features, n_estimators, max_depth. Specify the scoring function as 'roc_auc'. For cross validation, initialize and use KFold with 5 splits and shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the GridSearchCV using the training data and identify the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the score for the best estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Add other categorical and quantitative features to the model i.e. status_type, character and word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
